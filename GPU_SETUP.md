# üöÄ GPU Setup –∑–∞ Ollama

## **üìã –ò–∑–∏—Å–∫–≤–∞–Ω–∏—è**

### **1. NVIDIA GPU Driver**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏ –¥–∞–ª–∏ –∏–º–∞—à NVIDIA GPU
nvidia-smi
```

### **2. Docker —Å GPU –ø–æ–¥–¥—Ä—ä–∂–∫–∞**
```bash
# –ò–Ω—Å—Ç–∞–ª–∏—Ä–∞–π NVIDIA Container Toolkit
# Windows: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker-desktop

# –ò–ª–∏ –∏–∑–ø–æ–ª–∑–≤–∞–π Docker Desktop —Å WSL2 + NVIDIA drivers
```

### **3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ GPU –≤ Docker**
```bash
# –¢–µ—Å—Ç –∑–∞ GPU –ø–æ–¥–¥—Ä—ä–∂–∫–∞
docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
```

## **üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è**

### **1. Ollama —Å GPU**
```yaml
# docker-compose.yml
ollama:
  image: ollama/ollama:latest
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]
  environment:
    OLLAMA_FLASH_ATTENTION: true  # GPU acceleration
```

### **2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ GPU –≤ Ollama**
```bash
# –í–ª–µ–∑ –≤ Ollama –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
docker exec -it mini-rag-ollama bash

# –ü—Ä–æ–≤–µ—Ä–∏ GPU
nvidia-smi

# –ü—Ä–æ–≤–µ—Ä–∏ Ollama GPU –ø–æ–¥–¥—Ä—ä–∂–∫–∞
ollama list
```

## **‚ö° Performance –û—á–∞–∫–≤–∞–Ω–∏—è**

### **üöÄ –° GPU:**
- **Model loading:** ~5-10s (vs 30-60s CPU)
- **Inference speed:** ~3-5x –ø–æ-–±—ä—Ä–∑–æ
- **Memory usage:** –ü–æ-–µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ
- **Concurrent requests:** –ü–æ-–¥–æ–±—Ä–æ

### **üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ:**
| –ú–µ—Ç—Ä–∏–∫–∞ | CPU | GPU |
|---------|-----|-----|
| Model load | 30-60s | 5-10s |
| First token | 2-5s | 0.5-1s |
| Tokens/sec | 5-10 | 20-50 |
| Memory | 2-4GB | 1-2GB |

## **üõ† Troubleshooting**

### **‚ùå GPU –Ω–µ —Å–µ –≤–∏–∂–¥–∞:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏ NVIDIA drivers
nvidia-smi

# –ü—Ä–æ–≤–µ—Ä–∏ Docker GPU –ø–æ–¥–¥—Ä—ä–∂–∫–∞
docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
```

### **‚ùå Windows Docker Desktop:**
```bash
# Windows Docker Desktop –Ω–µ –ø–æ–¥–¥—ä—Ä–∂–∞ GPU –¥–∏—Ä–µ–∫—Ç–Ω–æ
# –ó–∞ GPU –ø–æ–¥–¥—Ä—ä–∂–∫–∞ –Ω–∞ Windows:
# 1. –ò–∑–ø–æ–ª–∑–≤–∞–π WSL2 —Å NVIDIA drivers
# 2. –ò–ª–∏ –∏–Ω—Å—Ç–∞–ª–∏—Ä–∞–π Ollama –¥–∏—Ä–µ–∫—Ç–Ω–æ –Ω–∞ Windows
# 3. –ò–ª–∏ –∏–∑–ø–æ–ª–∑–≤–∞–π CPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (–ø–æ-–¥–æ–ª—É)
```

### **‚ùå Ollama –Ω–µ –∏–∑–ø–æ–ª–∑–≤–∞ GPU:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏ Ollama logs
docker logs mini-rag-ollama

# –ü—Ä–æ–≤–µ—Ä–∏ GPU –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
docker exec -it mini-rag-ollama nvidia-smi
```

### **‚ùå CUDA –≥—Ä–µ—à–∫–∏:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏ CUDA –≤–µ—Ä—Å–∏—è
nvidia-smi

# –ü—Ä–æ–≤–µ—Ä–∏ Ollama CUDA –ø–æ–¥–¥—Ä—ä–∂–∫–∞
docker exec -it mini-rag-ollama ollama --version
```

## **üéØ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è**

### **1. Model Selection:**
- **Qwen2.5:1.5b** - –¥–æ–±—ä—Ä –±–∞–ª–∞–Ω—Å –∑–∞ GPU
- **Phi-3.5-mini** - –ø–æ-–±—ä—Ä–∑ –Ω–∞ GPU
- **Llama3.2:3b** - –ø–æ-–¥–æ–±—Ä–æ –∫–∞—á–µ—Å—Ç–≤–æ

### **2. GPU Settings:**
```yaml
environment:
  OLLAMA_FLASH_ATTENTION: true
  OLLAMA_NUM_PARALLEL: 1
  OLLAMA_MAX_LOADED_MODELS: 1
  OLLAMA_KEEP_ALIVE: 5m
```

### **3. CPU Settings (Windows Docker Desktop):**
```yaml
environment:
  OLLAMA_FLASH_ATTENTION: false  # Disabled for Windows
  OLLAMA_NUM_THREADS: 8  # Increased for CPU
  OLLAMA_NUM_PARALLEL: 1
  OLLAMA_MAX_LOADED_MODELS: 1
  OLLAMA_KEEP_ALIVE: 5m
```

### **3. Memory Management:**
```bash
# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –Ω–∞ GPU –ø–∞–º–µ—Ç
nvidia-smi -l 1

# –û—Å–≤–æ–±–æ–∂–¥–∞–≤–∞–Ω–µ –Ω–∞ –ø–∞–º–µ—Ç
docker restart mini-rag-ollama
```

## **‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞**

### **1. –°—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ —Å GPU:**
```bash
cd docker
docker-compose up -d ollama
```

### **2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ GPU:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏ GPU –∏–∑–ø–æ–ª–∑–≤–∞–Ω–µ
nvidia-smi

# –ü—Ä–æ–≤–µ—Ä–∏ Ollama logs
docker logs mini-rag-ollama
```

### **3. –¢–µ—Å—Ç –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç:**
```bash
# –¢–µ—Å—Ç –∑–∞—è–≤–∫–∞
curl -X POST http://localhost:8000/api/query \
  -H "Content-Type: application/json" \
  -d '{"q":"–¢–µ—Å—Ç –Ω–∞ GPU –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç", "k":3}'
```

## **üéâ –†–µ–∑—É–ª—Ç–∞—Ç**

–° GPU —Ç—Ä—è–±–≤–∞ –¥–∞ –≤–∏–¥–∏—à:
- **–ü–æ-–±—ä—Ä–∑–æ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ** –Ω–∞ –º–æ–¥–µ–ª–∞
- **–ü–æ-–±—ä—Ä–∑–∏ –æ—Ç–≥–æ–≤–æ—Ä–∏** (3-5x)
- **–ü–æ-–Ω–∏—Å–∫–æ CPU –∏–∑–ø–æ–ª–∑–≤–∞–Ω–µ**
- **–ü–æ-–¥–æ–±—Ä–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç** –ø—Ä–∏ –º–Ω–æ–≥–æ –∑–∞—è–≤–∫–∏

**Perfect! üöÄ** –°–µ–≥–∞ Ollama —â–µ –∏–∑–ø–æ–ª–∑–≤–∞ GPU –∑–∞ –∑–Ω–∞—á–∏—Ç–µ–ª–Ω–æ –ø–æ-–±—ä—Ä–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–Ω–æ—Å—Ç!
